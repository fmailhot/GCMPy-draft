{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workspace for string documentation\n",
    "Still very much in progress! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from scipy.optimize import minimize\n",
    "import seaborn as sns\n",
    "sns.set(style='ticks', context='paper')\n",
    "colors=[\"#e3c934\",\"#68c4bf\",\"#c51000\",\"#287271\"]\n",
    "sns.set_palette(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb52=pd.read_csv('pb52.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HzToBark(cloud,formants):\n",
    "    '''\n",
    "    Convert selected columns from Hz to Bark scale. Renames the formants as z.\n",
    "    Returns the data frame with additional columns: the value of the formant\n",
    "    converted from Hz to Bark\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    cloud = dataframe of exemplars \n",
    "    \n",
    "    formants = list of formants to be converted \n",
    "    '''\n",
    "    # Make a copy of the cloud\n",
    "    newcloud=cloud.copy()\n",
    "    \n",
    "    # For each formant listed, make a copy of the column prefixed with z\n",
    "    for formant in formants:\n",
    "        for ch in formant:\n",
    "            if ch.isnumeric():\n",
    "            num=ch\n",
    "        formantchar = (formant.split(num)[0])\n",
    "        name = str(formant).replace(formantchar,'z')\n",
    "        # Convert each value from Hz to Bark\n",
    "        newcloud[name] = 26.81/ (1+ 1960/newcloud[formant]) - 0.53\n",
    "    # Return the dataframe with the changes\n",
    "    return newcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(testset,cloud,dims,c=0.01):\n",
    "    '''\n",
    "    Calculate activation for all exemplars stored in the cloud\n",
    "    with respect to some stimulus, referred to as test. Returns\n",
    "    a data frame with column 'a' added for each row.\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    testset = a dataframe with one or more rows, each a stimulus to be categorized\n",
    "        must have columns matching those given in the 'dims' dict. These columns\n",
    "        should be dimensions of the stimulus (e.g., formants)\n",
    "        \n",
    "    cloud = A dataframe of stored exemplars which every stimulus is compared to. \n",
    "        Each row is an exemplar, which, like testset should have columns matching\n",
    "        those in the dims dict\n",
    "    \n",
    "    dims = a dictionary with dimensions as keys and weights, w, as values. \n",
    "    \n",
    "    c = an integer representing exemplar sensitivity. Defaults to .01. \n",
    "        \n",
    "    '''\n",
    "    # Get stuff ready                                                   \n",
    "    dims.update((x, (y/sum(dims.values()))) for x, y in dims.items())   # Normalize weights to sum to 1\n",
    "    \n",
    "    # If the testset happens to have N in it, remove it before joining dfs \n",
    "    test=testset.copy()\n",
    "    if 'N' in test.columns:\n",
    "        test = test.drop(columns='N', axis=1,inplace=True)\n",
    "    \n",
    "    exemplars=cloud.copy()\n",
    "\n",
    "    # Merge test and exemplars\n",
    "    bigdf = pd.merge(\n",
    "        test.assign(key=1),         # Add column named 'key' with all values == 1\n",
    "        exemplars.assign(key=1),    # Add column named 'key' with all values == 1\n",
    "        on='key',                   # Match on 'key' to get cross join (cartesian product)\n",
    "        suffixes=['_t', '_ex']\n",
    "    ).drop('key', axis=1)           # Drop 'key' column\n",
    "    \n",
    "    \n",
    "    dimensions=list(dims.keys())                # Get dimensions from dictionary\n",
    "    weights=list(dims.values())                 # Get weights from dictionary\n",
    "    tcols = [f'{d}_t' for d in dimensions]      # Get names of all test columns\n",
    "    excols = [f'{d}_ex' for d in dimensions]    # Get names of all exemplar columns\n",
    "    \n",
    "    \n",
    "    # Multiply each dimension by weights\n",
    "    i = bigdf.loc[:, tcols].values.astype(float)     # Get all the test columns\n",
    "    i *= weights                                     # Multiply test columns by weight\n",
    "    j = bigdf.loc[:, excols].values.astype(float)    # Get all the exemplar columns\n",
    "    j *= weights                                     # Multiply exemplar columns by weights\n",
    "    \n",
    "    # Get Euclidean distance\n",
    "    bigdf['dist'] = np.sqrt(np.sum((i-j)**2, axis=1))\n",
    "    \n",
    "    # get activation: exponent of negative distance * sensitivity c, multiplied by N_j\n",
    "    bigdf['a'] = np.exp(-bigdf.dist*c)*bigdf.N\n",
    "    \n",
    "    return bigdf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude(cloud, test, exclude_self=True, alsoexclude=None): \n",
    "    '''\n",
    "    Removes specific rows from the cloud of exemplars, to be used\n",
    "    prior to calculating activation. Prevents activation from being\n",
    "    overpowered by stimuli that are too similar to particular exemplars.\n",
    "    E.g., prevents comparison of a stimulus to itself, or to exemplars from same speaker\n",
    "    Returns dataframe containing a subset of rows from the cloud.\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    cloud = A dataframe of stored exemplars which every stimulus is compared to. \n",
    "        Each row is an exemplar\n",
    "    \n",
    "    test = single row dataframe containing the stimulus to be categorized\n",
    "    \n",
    "    exclude_self = boolean. If True, stimulus will be removed from exemplar cloud\n",
    "        so that it isn't compared to itself. Defaults to True \n",
    "    \n",
    "    Optional parameters:\n",
    "    \n",
    "    alsoexclude = a list of strings matching columns in the cloud (categories) to exclude \n",
    "        if value is the same as that of the test. (E.g., to exclude all exemplars from\n",
    "        the speaker to simulate categorization of novel speaker)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    # cloud = exemplars, dataframe\n",
    "    # test = exemplar to be categorized\n",
    "    # exclude_self = true or false, should the exemplar not be compared to itself? default true\n",
    "    # exclude = a list of columns in cloud to also exclude\n",
    "    \n",
    "    # Make a copy of the cloud and call it exemplars. \n",
    "    #    This is what we'll return at the end\n",
    "    exemplars = cloud.copy()\n",
    "    \n",
    "    # Remove the stimulus from the cloud\n",
    "    if exclude_self == True:\n",
    "        exemplars=cloud[~cloud.isin(test)].dropna()  \n",
    "    \n",
    "    if alsoexclude != None:\n",
    "        for feature in alsoexclude:\n",
    "            featval=test[feature].iloc[0]\n",
    "            exclude_exemps=exemplars[ exemplars[feature] == featval ].index\n",
    "            exemplars.drop(exclude_exemps, inplace=True)\n",
    "        \n",
    "    return exemplars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_N(exemplars, N=1):      # Add or override N, default to 1\n",
    "    '''\n",
    "    Adds an N (base activation) column to the exemplar cloud so\n",
    "    that activation with respect to the stimulus can be calculated\n",
    "    Default value is 1, i.e., equal activation for each exemplar.\n",
    "    Returns the exemplar data frame with added or reset column\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    exemplars = data frame of exemplars to which the stimulus is being\n",
    "        compared\n",
    "        \n",
    "    N = integer indicating the base activation value to be added to\n",
    "        each exemplar (row) in the dataframe. Defaults to 1.\n",
    "    '''\n",
    "    if type(N) == int:\n",
    "        extemp = exemplars.copy()\n",
    "        extemp['N'] = N\n",
    "    return extemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_N(exemplars, cat, catbias):\n",
    "    '''\n",
    "    Adds or overwrites an N (base activation) colummn to the exemplar \n",
    "    cloud so that activation with respect to the stimulus can be \n",
    "    calculated. Unlike reset_N, which assigns the same N value to all exemplars,\n",
    "    bias_N will set N values according to values in a dictionary. That is, within a \n",
    "    category type, each category will have the N value specified in the dictionary\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    exemplars = dataframe of exemplars to which the stimulus is being compared\n",
    "    \n",
    "    cat = a string designating the category type which is being primed\n",
    "    \n",
    "    catbias = dictionary with categories (e.g. vowels) as keys and N value for the  \n",
    "        category as values\n",
    "    '''\n",
    "    \n",
    "    def bias_N(exemplars, cat, catbias, N=1): \n",
    "    extemp = exemplars.copy()\n",
    "    extemp['N'] = N \n",
    "    extemp['N'] = extemp['N'] * extemp[cat].map(catbias)\n",
    "    return extemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probs(bigdf,cats):\n",
    "    \n",
    "    '''\n",
    "    Calculates the probability that the stimulus will be categorized with a\n",
    "    particular label for a given category (e.g., vowel labels 'i', 'a', 'u' for\n",
    "    the category 'vowel'). Probability is calculated by summing the activation\n",
    "    across all exemplars sharing a label, and dividing that by the total amount\n",
    "    of activation in the system for the category. Returns a dictionary of dictionaries.\n",
    "    Each key is a category; values are dictionaries where keys are labels and values\n",
    "    represent probability of the stimulus being categorized into that label.\n",
    "    \n",
    "    Required parameters: \n",
    "    \n",
    "    bigdf = a dataframe produced by activation(), which contains a row for each\n",
    "        exemplar with the additional column 'a' representing the amount of \n",
    "        activation for that exemplar with respect to the stimulus\n",
    "    \n",
    "    cats = a list of strings containing at least one item, indicating which\n",
    "        categories probability should be calculated for (e.g. ['vowel','gender']).\n",
    "        Items should match the name of columns in the data frame\n",
    "    '''\n",
    "    prs = {}\n",
    "    \n",
    "    # Loop over every category in the list of categories\n",
    "    for cat in cats: \n",
    "        # make that category match the exemplar category in name\n",
    "        label = cat+'_ex'\n",
    "        # Sum up activation for every label within that category\n",
    "        cat_a = bigdf.groupby(label).a.sum()\n",
    "        # Divide the activation for each label by the total activation for that category\n",
    "        pr = cat_a/sum(cat_a)\n",
    "        # rename a for activation to probability\n",
    "        pr = pr.rename_axis(cat).reset_index().rename(columns={\"a\":\"probability\"})\n",
    "        # add this to the dictionary \n",
    "        prs[cat]=pr\n",
    "    return prs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose(pr,test,cats,runnerup=False):\n",
    "    '''\n",
    "    Chooses a label for each category which the stimulus will be categorized as.\n",
    "    Returns the test/stimulus dataframe with added columns showing what was \n",
    "    chosen for a category and with what probability. Optionally will give the\n",
    "    second most probable label as well. \n",
    "    \n",
    "    Required parameters:\n",
    "    pr = dictionary of probabilities, given from probs(). Each key should represent\n",
    "        a category (e.g. 'vowel'), with values as dictionaries with keys for category\n",
    "        labels (e.g. 'i','a','u')\n",
    "        \n",
    "    test = single line data frame representing the test/stimulus being categorized\n",
    "        \n",
    "    cats = a list of strings containing at least one item, indicating which\n",
    "        categories probability should be calculated for (e.g. ['vowel','gender']).\n",
    "        Items should match the name of columns in the data frame\n",
    "            \n",
    "    Optional parameters:\n",
    "    runnerup = boolean; when true the label with the second highest probability\n",
    "        will also be included in the dataframe. Defaults to False. \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    newtest = test.copy()\n",
    "\n",
    "    for cat in cats:\n",
    "        choicename = cat + 'Choice'\n",
    "        choiceprobname = cat + 'Prob'\n",
    "        \n",
    "        best2 = pr[cat]['probability'].nlargest(n=2).reset_index(drop=True)        # Get the two highest probs for each cat type\n",
    "        \n",
    "        choiceprob = best2[0]                                                      # Match the prob to the category\n",
    "        choice = pr[cat].loc[pr[cat]['probability']==choiceprob,cat].iloc[0]\n",
    "        \n",
    "        newtest[choicename] = choice\n",
    "        newtest[choiceprobname] = choiceprob\n",
    "        \n",
    "        if runnerup == True: \n",
    "            choice2name = cat + 'Choice2'\n",
    "            choice2probname = cat +'Choice2Prob'\n",
    "            choice2prob = best2[1]                                                      \n",
    "            choice2 = pr[cat].loc[pr[cat]['probability']==choice2prob,cat].iloc[0]\n",
    "            newtest[choice2name] = choice2\n",
    "            newtest[choice2probname] = choice2prob\n",
    "            \n",
    "    return newtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettestset(cloud,balcat,n):     #Gets n number of rows per cat in given cattype\n",
    "    '''\n",
    "    Gets a random test set of stimuli to be categorized balanced across a particular\n",
    "    category, e.g., 5 instances of each label 'i','a', 'u' for category 'vowel'. \n",
    "    Returns a data frame of stimuli.\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    cloud = dataframe of exemplars\n",
    "        \n",
    "    balcat = category stimuli should be balanced across \n",
    "        \n",
    "    n = number of stimuli per category label to be included\n",
    "    '''\n",
    "    testlist=[]\n",
    "    for cat in list(cloud[balcat].unique()):\n",
    "        samp = cloud[cloud[balcat]==cat].sample(n)\n",
    "        testlist.append(samp)\n",
    "    test=pd.concat(testlist)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(testset,cloud,cats,dims,c,exclude_self=True,alsoexclude=None, N=1, runnerup=False):\n",
    "    '''\n",
    "    Categorizes a stimulus based on functions defined in library. \n",
    "    1. Exclude any desired stimuli\n",
    "    2. Add N value\n",
    "    3. Calculate activation\n",
    "    4. Calculate probabilities\n",
    "    5. Choose labels for each category\n",
    "    Returns the output of choose(): test/stimulus dataframe with added columns showing what was \n",
    "    chosen for a category and with what probability\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    testset = a dataframe with one row, a stimulus to be categorized\n",
    "        must have columns matching those given in the 'dims' dict. These columns\n",
    "        should be dimensions of the stimulus (e.g., formants)\n",
    "        \n",
    "    cloud = A dataframe of stored exemplars which every stimulus is compared to. \n",
    "        Each row is an exemplar, which, like testset should have columns matching\n",
    "        those in the dims dict\n",
    "        \n",
    "    cats = a list of strings containing at least one item, indicating which\n",
    "        categories probability should be calculated for (e.g. ['vowel','gender']).\n",
    "        Items should match the name of columns in the data frame\n",
    "    \n",
    "    dims = a dictionary with dimensions as keys and weights, w, as values. \n",
    "    \n",
    "    c = an integer representing exemplar sensitivity. Defaults to .01. \n",
    "    \n",
    "    exclude_self = boolean. If True, stimulus will be removed from exemplar cloud\n",
    "        so that it isn't compared to itself. Defaults to True \n",
    "        \n",
    "    Optional parameters:\n",
    "    alsoexclude = a list of strings matching columns in the cloud (categories) to exclude \n",
    "        if value is the same as that of the test. (E.g., to exclude all exemplars from\n",
    "        the speaker to simulate categorization of novel speaker)\n",
    "    \n",
    "    N = integer indicating the base activation value to be added to\n",
    "        each exemplar (row) in the dataframe. Defaults to 1\n",
    "        \n",
    "    runnerup = boolean; when true the label with the second highest probability\n",
    "        will also be included in the dataframe. Defaults to False.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    test=testset\n",
    "    exemplars=exclude(cloud,test,exclude_self=exclude_self,alsoexclude=alsoexclude)\n",
    "    reset_N(exemplars, N=N)\n",
    "    bigdf=activation(test,exemplars,dims=dims,c=c)\n",
    "    pr=probs(bigdf,cats)\n",
    "    choices=choose(pr,test,cats,runnerup=runnerup)\n",
    "    return choices \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getactiv(activation,x,y,cat):\n",
    "    \n",
    "    \"\"\" \n",
    "    Creates a simplified data frame showing the activation for each exemplar \n",
    "    with respect to the stimulus. Primarily for use with the activplot()\n",
    "    function. \n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    activation = DataFrame resulting from the activation() function, containing\n",
    "        one row per stored exemplar, with their activation 'a' as a column\n",
    "        \n",
    "    x = String. Dimension to be plotted as x axis in scatterplot (e.g., F2). Matches\n",
    "        the name of a column in the activation DataFrame.\n",
    "    \n",
    "    y = String. Dimension to be plotted as y axis in scatterplot (e.g., F1). Matches\n",
    "        the name of a column in the activation DataFrame.\n",
    "    \n",
    "    cat = String. Category used to color code exemplars in scatter plot. Matches the name\n",
    "        of a column in the activation DataFrame.\n",
    "    \"\"\"\n",
    "    xname = x + \"_ex\"\n",
    "    yname = y + \"_ex\"\n",
    "    catname = cat + \"_ex\"\n",
    "    \n",
    "    acts = activation['a']\n",
    "    xs = activation[xname]\n",
    "    ys = activation[yname]\n",
    "    cats = activation[catname]\n",
    "    \n",
    "    activ = pd.concat([acts,xs,ys,cats], axis=1)\n",
    "    activ.rename(columns={xname:x, yname:y, catname:cat}, inplace=True)\n",
    "    \n",
    "    return activ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activplot(a,x,y,cat,test):\n",
    "    \"\"\"\n",
    "    Plots each exemplar in x,y space according to specified dimensions. Labels within\n",
    "    the category are grouped by color. The stimulus or test exemplar is plotted in dark\n",
    "    blue on top of exemplars. Note: axes are inverted, assuming F1/F2 space\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    a = DataFrame produced by getactiv() function. Contains a row for each exemplar\n",
    "    \n",
    "    x = String. Dimension to be plotted as x axis in scatterplot (e.g., F2). Matches\n",
    "        the name of a column in the activation DataFrame.\n",
    "    \n",
    "    y = String. Dimension to be plotted as y axis in scatterplot (e.g., F1). Matches\n",
    "        the name of a column in the activation DataFrame.\n",
    "    \n",
    "    cat = String. Category used to color code exemplars in scatter plot. Matches the name\n",
    "        of a column in the activation DataFrame.\n",
    "    \n",
    "    test = name of test exemplar, one row of a DataFrame.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    pl = sns.scatterplot(data=a,x=x,y=y,hue=cat,size='a',size_norm=(0,a.a.max()),\n",
    "                     alpha=0.5,sizes=(5,100),legend=False)\n",
    "    pl = sns.scatterplot(data=test, x=x,y=y,alpha=.5,color='darkblue',marker=\"X\", s= 50, legend=False)\n",
    "    \n",
    "    pl.invert_xaxis()\n",
    "    pl.invert_yaxis()\n",
    "\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multicat(testset,cloud,cats,dims,c,exclude_self=True,alsoexclude=None, N=1, runnerup=False, bias=None):\n",
    "    '''\n",
    "    Categorizes a dataframe of multiple stimuli based on functions defined in library. \n",
    "    1. Exclude any desired stimuli\n",
    "    2. Add N value\n",
    "    3. Calculate activation\n",
    "    4. Calculate probabilities\n",
    "    5. Choose labels for each category\n",
    "    Returns the output of choose(): test/stimulus dataframe with added columns showing what was \n",
    "    chosen for a category and with what probability\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    testset = a dataframe with one or more rows, each a stimulus to be categorized\n",
    "        must have columns matching those given in the 'dims' dict. These columns\n",
    "        should be dimensions of the stimulus (e.g., formants)\n",
    "        \n",
    "    cloud = A dataframe of stored exemplars which every stimulus is compared to. \n",
    "        Each row is an exemplar, which, like testset should have columns matching\n",
    "        those in the dims dict\n",
    "        \n",
    "    cats = a list of strings containing at least one item, indicating which\n",
    "        categories probability should be calculated for (e.g. ['vowel','gender']).\n",
    "        Items should match the name of columns in the data frame\n",
    "        \n",
    "    dims = a dictionary with dimensions as keys and weights, w, as values. \n",
    "    \n",
    "    c = an integer representing exemplar sensitivity. Defaults to .01. \n",
    "    \n",
    "    exclude_self = boolean. If True, stimulus will be removed from exemplar cloud\n",
    "        so that it isn't compared to itself. Defaults to True \n",
    "        \n",
    "    Optional parameters:\n",
    "    alsoexclude = a list of strings matching columns in the cloud (categories) to exclude \n",
    "        if value is the same as that of the test. (E.g., to exclude all exemplars from\n",
    "        the speaker to simulate categorization of novel speaker)\n",
    "    \n",
    "    N = integer indicating the base activation value to be added to\n",
    "        each exemplar (row) in the dataframe. Defaults to 1\n",
    "        \n",
    "    runnerup = boolean; when true the label with the second highest probability\n",
    "        will also be included in the dataframe. Defaults to False.\n",
    "    '''\n",
    "    \n",
    "    choicelist=[]\n",
    "    for ix in list(testset.index.values):\n",
    "        test = testset.loc[[ix,]]\n",
    "        exemplars=exclude(cloud,test,exclude_self=exclude_self,alsoexclude=alsoexclude)\n",
    "        exemplars = reset_N(exemplars,N=N)\n",
    "        bigdf=activation(test,exemplars,dims = dims,c=c)\n",
    "        pr=probs(bigdf,cats)\n",
    "        choices = choose(pr,test,cats,runnerup=runnerup)\n",
    "        choicelist.append(choices)\n",
    "    choices=pd.concat(choicelist, ignore_index=True)\n",
    "    return choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multicatprime(testset,cloud,cats,dims,c,cat,catbias,exclude_self=True,alsoexclude=None):\n",
    "    '''\n",
    "    Categorizes a dataframe of multiple stimuli based on functions defined in library, \n",
    "    much like multicat(), but rather than assigning one N value, use a dictionary of\n",
    "    category biases to assign N based on category membership.\n",
    "    \n",
    "    1. Exclude any desired stimuli\n",
    "    2. Add N value according to cat biases \n",
    "    3. Calculate activation\n",
    "    4. Calculate probabilities\n",
    "    5. Choose labels for each category\n",
    "    Returns the output of choose(): test/stimulus dataframe with added columns showing what was \n",
    "    chosen for a category and with what probability\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    testset = a dataframe with one or more rows, each a stimulus to be categorized\n",
    "        must have columns matching those given in the 'dims' dict. These columns\n",
    "        should be dimensions of the stimulus (e.g., formants)\n",
    "        \n",
    "    cloud = A dataframe of stored exemplars which every stimulus is compared to. \n",
    "        Each row is an exemplar, which, like testset should have columns matching\n",
    "        those in the dims dict\n",
    "        \n",
    "    cats = a list of strings containing at least one item, indicating which\n",
    "        categories probability should be calculated for (e.g. ['vowel','gender']).\n",
    "        Items should match the name of columns in the data frame\n",
    "        \n",
    "    dims = a dictionary with dimensions as keys and weights, w, as values. \n",
    "    \n",
    "    c = an integer representing exemplar sensitivity. Defaults to .01. \n",
    "    \n",
    "    cat = a string designating the category type which is being primed\n",
    "    \n",
    "    catbias = dictionary with categories (e.g. vowels) as keys and N value for the  \n",
    "        category as values\n",
    "    \n",
    "    exclude_self = boolean. If True, stimulus will be removed from exemplar cloud\n",
    "        so that it isn't compared to itself. Defaults to True \n",
    "        \n",
    "    Optional parameters:\n",
    "    alsoexclude = a list of strings matching columns in the cloud (categories) to exclude \n",
    "        if value is the same as that of the test. (E.g., to exclude all exemplars from\n",
    "        the speaker to simulate categorization of novel speaker)\n",
    "    \n",
    "    N = integer indicating the base activation value to be added to\n",
    "        each exemplar (row) in the dataframe. Defaults to 1\n",
    "        \n",
    "    runnerup = boolean; when true the label with the second highest probability\n",
    "        will also be included in the dataframe. Defaults to False.\n",
    "    '''\n",
    "    choicelist=[]\n",
    "    for ix in list(testset.index.values):\n",
    "        test = testset.loc[[ix,]]\n",
    "        exemplars=exclude(cloud,test,exclude_self=exclude_self,alsoexclude=alsoexclude)\n",
    "        # unlike multicat, which uses reset_N, here use bias_N \n",
    "        exemplars = bias_N(exemplars,cat,catbias)\n",
    "        bigdf=activation(test,exemplars,dims = dims,c=c)\n",
    "        pr=probs(bigdf,cats)\n",
    "        choices = choose(pr,test,cats)\n",
    "        choicelist.append(choices)\n",
    "    choices=pd.concat(choicelist, ignore_index=True)\n",
    "    return choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkaccuracy(choices,cats):\n",
    "    '''\n",
    "    Check rather the choices made my the model match the 'intended' label for each category.\n",
    "    Returns a copy of the testset dataframe with column added indicating whether the choice for\n",
    "    each category was correct (y) or incorrect (n)\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    choices = output of choose() function: the test/stimulus dataframe with added columns showing what was \n",
    "        chosen for a category and with what probability.\n",
    "    \n",
    "    cats = a list of strings containing at least one item, indicating which\n",
    "        categories probability was calculated for (e.g. ['vowel','gender']).\n",
    "        Items should match the name of columns in the data frame\n",
    "    '''\n",
    "    acc = choices.copy()                     # Make a copy of choices to muck around with\n",
    "    \n",
    "    for cat in cats:                     # Iterate over your list of cats\n",
    "        accname = cat + 'Acc'            # Get the right column names\n",
    "        choicename = cat + 'Choice'\n",
    "        \n",
    "        # If choice is the same as intended, acc =y, else n\n",
    "        acc[accname] = np.where(acc[cat]==acc[choicename], 'y', 'n')      \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propcorr(acc,cat):\n",
    "    '''\n",
    "    Calculates the proportion of stimuli under each label which were categorized correctly\n",
    "    Returns a dataframe with keys as labels and values as proportions between 0 and 1.\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    acc = output of checkaccuracy() function: a copy of the testset dataframe with column\n",
    "        added indicating whether the choice for each category was correct (y) or incorrect (n)\n",
    "        \n",
    "    cat = string ndicating which category accuracy should be assessed for. String should match\n",
    "        column in acc.\n",
    "    '''\n",
    "    perc = dict(acc.groupby(cat)[cat+'Acc'].value_counts(normalize=True).drop(labels='n',level=1).reset_index(level=1,drop=True))\n",
    "    pc=pd.DataFrame.from_dict(perc, orient='index').reset_index()\n",
    "    pc.columns=[cat,'propcorr']\n",
    "    return pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overallacc(acc,cat):\n",
    "    '''\n",
    "    Calculates accuracy for categorization overall, across all labels. Returns a \n",
    "    proportion between 0 and 1. \n",
    "    \n",
    "    Required parameters: \n",
    "    \n",
    "    acc = output of checkaccuracy() function: a copy of the testset dataframe with column\n",
    "        added indicating whether the choice for each category was correct (y) or incorrect (n)\n",
    "        \n",
    "    cat = string ndicating which category accuracy should be assessed for. String should match\n",
    "        column in acc.\n",
    "    '''\n",
    "    \n",
    "    totalcorrect = acc[cat+'Acc'].value_counts(normalize=True)['y']\n",
    "    return totalcorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accplot(acc,cat):\n",
    "    '''\n",
    "    Plots a bar graph showing the proportion of trials which were categorized\n",
    "    veridically, that is, accuracy of categorization.\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    acc = output of checkaccuracy() function: a copy of the testset dataframe with column\n",
    "        added indicating whether the choice for each category was correct (y) or incorrect (n)\n",
    "        \n",
    "    cat = string ndicating which category accuracy should be assessed for. String should match\n",
    "        column in acc.\n",
    "    \n",
    "    '''\n",
    "    perc = dict(acc.groupby(cat)[cat+'Acc'].value_counts(normalize=True).drop(labels='n',level=1).reset_index(level=1,drop=True))\n",
    "    pc=pd.DataFrame.from_dict(perc, orient='index').reset_index()\n",
    "    pc.columns=[cat,'propcorr']\n",
    "    \n",
    "    obs=str(len(acc))\n",
    "    pl = sns.barplot(x=cat,y='propcorr',data=pc,palette=colors)\n",
    "    plt.ylim(0,1.01)\n",
    "    pl.set(ylabel='Proportion accurate of '+obs+' trials')\n",
    "    pl.set_xticklabels(\n",
    "    pl.get_xticklabels(), \n",
    "    rotation=45, \n",
    "    horizontalalignment='right',\n",
    "    fontweight='light',\n",
    "    fontsize='x-large')\n",
    "    plt.show()\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiaccplot(choices,cats):\n",
    "    '''\n",
    "    Plots accuracy of multiple categories\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    choices = output of choose() function: the test/stimulus dataframe with added columns showing what was \n",
    "        chosen for a category and with what probability.\n",
    "    \n",
    "    cats = a list of strings containing at least one item, indicating which\n",
    "        categories probability was calculated for (e.g. ['vowel','gender']).\n",
    "        Items should match the name of columns in the data frame\n",
    "    '''\n",
    "    accuracy = checkaccuracy(choices,cats)\n",
    "    for cat in cats:\n",
    "        proportion = propcorr(accuracy,cat)\n",
    "        accplot(proportion,cat,accuracy)\n",
    "        print(proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion(choices,cats):\n",
    "    '''\n",
    "    Returns a confusion matrix comparing intended category with categorization.\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    choices = output of choose() function: the test/stimulus dataframe with added columns showing what was \n",
    "        chosen for a category and with what probability.\n",
    "    \n",
    "    cats = a list of strings containing at least one item, indicating which\n",
    "        categories probability was calculated for (e.g. ['vowel','gender']).\n",
    "        Items should match the name of columns in the data frame\n",
    "    '''\n",
    "    matrices={}\n",
    "    for cat in cats:\n",
    "        matrices[cat]=pd.crosstab(choices[cat],choices[cat+'Choice'],normalize='index').round(2).rename_axis(None)\n",
    "    return matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorfunc(x, testset, cloud, dimslist, cat):\n",
    "    ''' \n",
    "    Returns a proportion representing the total amount of error for a single category that\n",
    "    the categorizer makes given a certain set of c and w values. This is intended to\n",
    "    be used with an optimization function so that the total amount of error can be \n",
    "    minimized; that is, the accuracy can be maximized. \n",
    "    Note that z0 is automatically set to 1.\n",
    "    \n",
    "    Required parameters: \n",
    "    \n",
    "    x = a vector of values to be used by multicat. x[0] should be c, x[1], x[2], x[3]\n",
    "        should correspond to dimslist[1], dimslist[2], dimslist[3]\n",
    "        \n",
    "    testset = a dataframe with one or more rows, each a stimulus to be categorized\n",
    "        must have columns matching those given in the dims list. These columns\n",
    "        should be dimensions of the stimulus (e.g., formants)\n",
    "        \n",
    "    cloud = A dataframe of stored exemplars which every stimulus is compared to. \n",
    "        Each row is an exemplar, which, like testset should have columns matching\n",
    "        those in the dims list\n",
    "    \n",
    "    dimslist = a list of dimensions (e.g., formants), for which weights w should be given,\n",
    "        and along which exemplars should be compared.\n",
    "    \n",
    "    cat = the category, \n",
    "        \n",
    "    \n",
    "    '''\n",
    "    #x = [c,z1,z2,z3]\n",
    "    catlist=[cat]\n",
    "    c=x[0]\n",
    "    dimsdict={dimslist[0]:1,dimslist[1]:x[1],dimslist[2]:x[2],dimslist[3]:x[3]}\n",
    "    choices=multicat(cloud,testset,catlist,dims=dimsdict,c=c)\n",
    "    accuracy=checkaccuracy(choices,catlist)\n",
    "    err = accuracy[cat+'Acc'].value_counts(normalize=True)['n']\n",
    "    return err"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
